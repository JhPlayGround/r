#데이터 준비
# 데이터 선택 -> 전처리 -> 구성 -> 통합 ->포맷 변경

#모델화
# 모델화 기법 선택 -> 테스트 설계 생성 -> 모델 생성 -> 모델 평가

#평가
# 결과 평과 -> 과정 검토 -> 다음 단계 설정

#적용
# 계획 적용 -> 진행 계획의 감시와 유지, 보수 -> 최종 보고서 작성 -> 프로젝트 복기

# 데이터가 텍스트 인가?
# 텍스트 마이닝 (단어 빈도, 워드 클라우드 , 주제 모형(잠재적 디리슈레 분석, 어휘적분석(극 관계, 산포 등)))

# 시계열 데이터가 단변량의 데이터인가?
# 1) 예
# 단변량 예측 : 자기회귀 누적 이동 평균(ARIMA), 지수 평활, 선형 회귀,
#               자기회귀 조건부 이분산(ARCH), 일반 자기회귀 조건부 이분산(GARCH)
# 2) 아니오
# 다변량 예측 : 동적 선형 회귀, 자기 회귀 누적 이동 평균(ARIMAX), 전이함수, ARIMA
#             : 벡터 자기 회귀, 그랜저 인과관계, 벡터 오차 수정 모형(VECM), 공적분

#추천
# 추천 엔진 : 사용자 기반 협업 필터링, 아이템 기반 협업 필터링, 특이값 분해(SVD)
#           : 주성분 분해(PCA), 교차 최소 제곱법(ALS)

#연관성
# 연관성 분석(장바구니) : 선혐법, 상향적 격자 횡단법을 이용한 동치류 군집화(ECLAT)

#수치
# 수치 예측 : 선형 회귀, 라쏘(LASSO), 능형 회귀, 엘라스틱넷, 주성분 분석 회귀,
#           : 일반화 가법 모형(GAMs), 부분 최소 제곱법(PLS)

#데이터를 범주화하고 싶지만 데이터에 식별값이 없을때
# 군집화 
# 계층적 군집화, K-means 군집화, 중간점 군집화, 자기 조직화 지도(SOM)
# 퍼지 군집화, 밀도 기반 공간 군집법(DBSCAN)

#데이터를 범주화하고 식별값이 있는 경우
# 분류
# 로지스틱 회귀, 선형 판별 분석(LDA), K-최근접 이웃법(KNN)
# 서포트 벡터 머신, 신경망/딥러닝, 의사결정 트리
# 랜덤 포레스트, 그레이디언트 부스트, 나이브 베이즈, 생존 분석
